{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from sklearn.preprocessing import LabelEncoder\n"],"metadata":{"id":"cpv3oEMUQwLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model = tf.keras.models.load_model(\"model/skimlit_tribrid_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FBQ7OAD-SOuI","outputId":"2c2cc663-2638-4347-ca61-4f9a71e311b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Errno 2] No such file or directory: 'drive/My Drive/SC'\n","/content/drive/My Drive/SC\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHIVQ1ExMbM7"},"outputs":[],"source":["def classify(abstract):\n","\n","  target={0:'BACKGROUND', 1:'CONCLUSIONS', 2:'METHODS', 3:'OBJECTIVE', 4:'RESULTS'}\n","\n","  # Make function to split sentences into characters\n","  def split_chars(text):\n","    return \" \".join(list(text))\n","\n","\n","  # Create sentencizer - Source: https://spacy.io/usage/linguistic-features#sbd \n","  from spacy.lang.en import English\n","  nlp = English() # setup English sentence parser\n","  #sentencizer = nlp.create_pipe(\"sentencizer\") # create sentence splitting pipeline object\n","  nlp.add_pipe(nlp.create_pipe('sentencizer')) # add sentence splitting pipeline object to sentence parser\n","  doc = nlp(abstract) # create \"doc\" of parsed sequences, change index for a different abstract\n","  abstract_lines = [str(sent) for sent in list(doc.sents)] # return detected sentences from doc in string type (not spaCy token type)\n","  abstract_lines\n","\n","\n","  total_lines_in_sample = len(abstract_lines)\n","  # Go through each line in abstract and create a list of dictionaries containing features for each line\n","  sample_lines = []\n","  for i, line in enumerate(abstract_lines):\n","    sample_dict = {}\n","    sample_dict[\"text\"] = str(line)\n","    sample_dict[\"line_number\"] = i\n","    sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n","    sample_lines.append(sample_dict)\n","  sample_lines\n","\n","\n","  # Get all line_number values from sample abstract\n","  test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n","  # One-hot encode to same depth as training data, so model accepts right input shape\n","  test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15) \n","  test_abstract_line_numbers_one_hot\n","\n","\n","  # Get all total_lines values from sample abstract\n","  test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n","  # One-hot encode to same depth as training data, so model accepts right input shape\n","  test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n","  test_abstract_total_lines_one_hot\n","\n","  # Split abstract lines into characters\n","  abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n","  abstract_chars\n","\n","  # Make predictions on sample abstract features\n","  test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n","                                                   test_abstract_total_lines_one_hot,\n","                                                   tf.constant(abstract_lines),\n","                                                   tf.constant(abstract_chars)))\n","  test_abstract_pred_probs\n","\n","  # Turn prediction probabilities into prediction classes\n","  test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n","  test_abstract_preds=test_abstract_preds.numpy()\n","  test_abstract_preds\n","\n","  # Turn prediction class integers into string class names\n","  test_abstract_pred_classes = [target[i] for i in test_abstract_preds]\n","  test_abstract_pred_classes\n","\n","  s=\"\"\n","  for i in range (total_lines_in_sample):\n","    s=s+test_abstract_pred_classes[i]+\" : \"+abstract_lines[i]+\"\\n\"\n","    \n","  return s"]}]}